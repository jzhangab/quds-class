{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Notebook - Text Data Manipulation\n",
    "\n",
    "### Description\n",
    "The purpose of this notebook is to provide examples of common text data manipulations that can be used in Python to automate data processing tasks. The notebook will focus on the two most common types of text data: excel and csv. The following topics will be covered:\n",
    "\n",
    "1. Reading multiple excel files from the same directory\n",
    "2. Removing an excel header\n",
    "3. Combining multiple excel sheets vertically (concatenate)\n",
    "4. Removing duplicates\n",
    "5. Removing missing values\n",
    "6. Expanding 1 row with combined field into multiple rows\n",
    "7. Reading a csv file\n",
    "8. Merging excel data and csv data horizontally (join)\n",
    "9. Group by Date and count the number of unique PR's of each type\n",
    "10. Outputting to new excel or csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we must import the pandas package that we will use to read our files\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading multiple excel files from the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of excel filenames\n",
    "excel_filenames = [\"https://raw.githubusercontent.com/jzhangab/DS101/master/1_Data/Excel_demo/excel_demo_1.xlsx\",\n",
    "                   \"https://raw.githubusercontent.com/jzhangab/DS101/master/1_Data/Excel_demo/excel_demo_2.xlsx\",\n",
    "                   \"https://raw.githubusercontent.com/jzhangab/DS101/master/1_Data/Excel_demo/excel_demo_3.xlsx\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 + 3. Removing an excel header and combining multiple excel sheets vertically\n",
    "\n",
    "First let's read one of the files, try reading it with and without skipping the first 5 rows using the skiprows command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_excel = pd.read_excel(\"https://raw.githubusercontent.com/jzhangab/DS101/master/1_Data/Excel_demo/excel_demo_1.xlsx\",\n",
    "                           sheet_name = \"export_query_results\",\n",
    "                           skiprows = 5,\n",
    "                           engine = 'openpyxl') #Try setting skiprows to 0 or 1 and see what the df_1_excel looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command previews the start of the dataframe\n",
    "df_1_excel.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat is used to concatenate multiple dataframes\n",
    "df_excel = pd.concat((pd.read_excel(f,\n",
    "                                    sheet_name = \"export_query_results\",\n",
    "                                    skiprows = 5,\n",
    "                                   engine = 'openpyxl') for f in excel_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the resulting combined dataframe\n",
    "df_excel.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Remove duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = df_excel.drop_duplicates(keep = \"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = df_excel.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Expand a row into multiple rows based on delimited column\n",
    "We will expand the \";\" delimited column [Type] into multiple rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convert [Type] into list form\n",
    "df_excel['Type'] = df_excel['Type'].str.split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then explode the column\n",
    "df_excel = df_excel.explode('Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataframe\n",
    "df_excel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Read a single CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv(\"https://raw.githubusercontent.com/jzhangab/DS101/master/1_Data/Excel_demo/map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Merging excel data and csv data horizontally (join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a left join\n",
    "df_merge = pd.merge(df_excel,\n",
    "                    df_csv,\n",
    "                    left_on = 'PR ID',\n",
    "                    right_on = 'PR',\n",
    "                    how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Group by Date and count the number of unique PR's of each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df_merge.groupby(['Date', 'Type']).count()\n",
    "df_group = df_group[['PR ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Output to excel or csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group.to_csv('thisisacsvfile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And if you want to read the file you just output\n",
    "pd.read_csv('thisisacsvfile.csv')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
